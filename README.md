### Chat com Modelo Llama2 via Ollama usando Streamlit
---

Este projeto consiste em uma aplicação de chatbot chamada Chat Ollama que utiliza o modelo de linguagem Llama2 para responder a consultas dos usuários. A interface da aplicação é desenvolvida com Streamlit, permitindo uma interação simples e intuitiva.

#### Funcionalidades Principais:

- **Chatbot com Modelo Llama2**: O chatbot é alimentado pelo modelo Llama2, treinado para entender e responder uma ampla variedade de consultas em linguagem natural.
  
- **Interface Web com Streamlit**: A aplicação é acessível por meio de uma interface web desenvolvida com Streamlit. Os usuários podem interagir com o chatbot diretamente no navegador.

- **Respostas Inteligentes**: O modelo Llama2 é capaz de fornecer respostas inteligentes e relevantes para uma variedade de perguntas e solicitações.

#### Como Usar:

1. **Instalação**:
   - Clone este repositório:
     ```bash
     git clone https://github.com/seu-usuario/chat-ollama
     ```
   - Instale as dependências:
     ```bash
     cd chat-ollama
     pip install -r requirements.txt
     ```

2. **Execução**:
   - Inicie a aplicação com o Streamlit:
     ```bash
     streamlit run app.py
     ```
   - O aplicativo será aberto em seu navegador padrão.

3. **Interagindo com o Chatbot**:
   - Digite suas perguntas ou mensagens na caixa de entrada do chat.
   - Aguarde as respostas do chatbot, que serão exibidas na interface.

